{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day6 - Removing Outliers 1 (actually was a wrong way)\n",
    "\n",
    "Yesterday, I tried stacking method, but I think the way I tuned hyperparameters were not optimal and I did not get a good score. \n",
    "\n",
    "Today, I am going to try removing outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_final.csv')\n",
    "X_pred_data = pd.read_csv('test_final.csv')\n",
    "X_pred = np.asarray(X_pred_data.iloc[:, 1:25]).reshape(-1, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(data.iloc[:, 2:26]).reshape(-1, 24)\n",
    "y = np.asarray(data.iloc[:, 1]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = []\n",
    "std = []\n",
    "for i in range(X.shape[1]):\n",
    "    mean.append(np.mean(X[:, i]))\n",
    "    std.append(np.std(X[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, feature 23 has a bad sample. Actually I already found it. It's sample 4664, value is 404288627. This is eroding the quality of model.\n",
    "\n",
    "Now I have to find a way to remove that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    plt.plot(X[:, i])\n",
    "    plt.title('feature' + str(i+1) + \"   $\\mu$ : %.1f     $\\sigma$ : %.1f\" %(mean[i], std[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outliers = []\n",
    "for i in range(X.shape[1]):\n",
    "    count = 0\n",
    "    for j in range(X.shape[0]):\n",
    "        if(X[j][i] > mean[i] + 3.5*std[i] or X[j][i] < mean[i] - 3.5*std[i]):\n",
    "            count += 1\n",
    "    num_outliers.append(count*100/X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 1     outliers :    0.70 %\n",
      "feature 2     outliers :    3.52 %\n",
      "feature 3     outliers :    0.08 %\n",
      "feature 4     outliers :    0.42 %\n",
      "feature 5     outliers :    3.59 %\n",
      "feature 6     outliers :    0.71 %\n",
      "feature 7     outliers :    0.71 %\n",
      "feature 8     outliers :    0.00 %\n",
      "feature 9     outliers :    3.32 %\n",
      "feature 10     outliers :    0.28 %\n",
      "feature 11     outliers :    3.46 %\n",
      "feature 12     outliers :    0.13 %\n",
      "feature 13     outliers :    0.70 %\n",
      "feature 14     outliers :    0.20 %\n",
      "feature 15     outliers :    0.96 %\n",
      "feature 16     outliers :    2.33 %\n",
      "feature 17     outliers :    0.00 %\n",
      "feature 18     outliers :    0.61 %\n",
      "feature 19     outliers :    3.27 %\n",
      "feature 20     outliers :    3.55 %\n",
      "feature 21     outliers :    3.71 %\n",
      "feature 22     outliers :    3.46 %\n",
      "feature 23     outliers :    0.03 %\n",
      "feature 24     outliers :    3.57 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    print(\"feature \" + str(i+1) + \"     outliers :    %.2f \" %num_outliers[i] + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above data is showing how much portion of samples are out of 3.5$\\sigma$ (i.e. standard deviation) range, if assumed to benormal distribution.\n",
    "\n",
    "In normal distribution, it can be computed that $P(X>3.5\\sigma\\ or\\ X<-3.5\\sigma) = 0.00046\\  or\\  0.046%$. So, by comparing above values with this 0.046, I can get some idea if the feature came from a normal distribution or not. As below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 1     outliers :    0.696 %.  ->  Not\n",
      "feature 2     outliers :    3.516 %.  ->  Not\n",
      "feature 3     outliers :    0.079 %.  ->  Not\n",
      "feature 4     outliers :    0.421 %.  ->  Not\n",
      "feature 5     outliers :    3.589 %.  ->  Not\n",
      "feature 6     outliers :    0.708 %.  ->  Not\n",
      "feature 7     outliers :    0.708 %.  ->  Not\n",
      "feature 8     outliers :    0.000 %.  ->  Normal Distribution\n",
      "feature 9     outliers :    3.321 %.  ->  Not\n",
      "feature 10     outliers :    0.281 %.  ->  Not\n",
      "feature 11     outliers :    3.461 %.  ->  Not\n",
      "feature 12     outliers :    0.134 %.  ->  Not\n",
      "feature 13     outliers :    0.702 %.  ->  Not\n",
      "feature 14     outliers :    0.201 %.  ->  Not\n",
      "feature 15     outliers :    0.958 %.  ->  Not\n",
      "feature 16     outliers :    2.332 %.  ->  Not\n",
      "feature 17     outliers :    0.000 %.  ->  Normal Distribution\n",
      "feature 18     outliers :    0.610 %.  ->  Not\n",
      "feature 19     outliers :    3.272 %.  ->  Not\n",
      "feature 20     outliers :    3.552 %.  ->  Not\n",
      "feature 21     outliers :    3.711 %.  ->  Not\n",
      "feature 22     outliers :    3.461 %.  ->  Not\n",
      "feature 23     outliers :    0.031 %.  ->  Normal Distribution\n",
      "feature 24     outliers :    3.571 %.  ->  Not\n"
     ]
    }
   ],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    if(num_outliers[i] <= 0.046): # 0.135\n",
    "        print(\"feature \" + str(i+1) + \"     outliers :    %.3f \" %num_outliers[i] + \"%.  ->  Normal Distribution\")\n",
    "    else:\n",
    "        print(\"feature \" + str(i+1) + \"     outliers :    %.3f \" %num_outliers[i] + \"%.  ->  Not\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, it turned out that features 8, 17, 23 are normal distribution.\n",
    "\n",
    "Now, I will remove \"outliers\" for these 3 columns. For other features, I can't remove outliers so easily as they might not be normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because of feature 23, deleted row 645.    Deleted value : 17681416.000\n",
      "because of feature 23, deleted row 2995.    Deleted value : 42640756.000\n",
      "because of feature 23, deleted row 4661.    Deleted value : 404288627.000\n",
      "because of feature 23, deleted row 6044.    Deleted value : 17241070.000\n",
      "because of feature 23, deleted row 8739.    Deleted value : 12860243.000\n"
     ]
    }
   ],
   "source": [
    "for i in [7, 16, 22]:\n",
    "    j = 0\n",
    "    while (j < X.shape[0]):\n",
    "        if(X[j][i] > mean[i] + 3.5*std[i] or X[j][i] < mean[i] - 3.5*std[i]):\n",
    "            val = X[j][i]\n",
    "            X = np.delete(X, j, 0)\n",
    "            y = np.delete(y, j, 0)\n",
    "            print(\"because of feature %d, deleted row %d.    Deleted value : %.3f\" %(i+1, j, val))\n",
    "        else:\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I have deleted 5 samples which are pretty bad. I think they corrupted the data, and caused lower score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb0 = xgb.XGBClassifier(colsample_bytree=0.65, gamma=0.1,\n",
    "       learning_rate=0.05, max_depth=5,\n",
    "       min_child_weight=5, n_estimators=1000, objective='binary:logistic',\n",
    "      reg_alpha=1, reg_lambda=1,\n",
    "      subsample=0.85, verbosity=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb0.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %f' % metrics.accuracy_score(y_test, xgb.predict(X_test)))\n",
    "print('AUC: %f' %metrics.roc_auc_score(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission20 = pd.DataFrame(xgb.predict_proba(X_pred)[:, 1], columns = ['Y']) \n",
    "y_submission20['Id'] = X_pred_data['Id']\n",
    "y_submission20 = y_submission20.reindex(columns=[\"Id\", \"Y\"])\n",
    "y_submission20.to_csv(\"submission20_uk734.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I think I can try to remove more outliers, by trying $X>3\\sigma\\ or\\ X<-3\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 1     outliers :    0.696 %.  ->  Not\n",
      "feature 2     outliers :    3.516 %.  ->  Not\n",
      "feature 3     outliers :    0.079 %.  ->  Normal Distribution\n",
      "feature 4     outliers :    0.421 %.  ->  Not\n",
      "feature 5     outliers :    3.589 %.  ->  Not\n",
      "feature 6     outliers :    0.708 %.  ->  Not\n",
      "feature 7     outliers :    0.708 %.  ->  Not\n",
      "feature 8     outliers :    0.000 %.  ->  Normal Distribution\n",
      "feature 9     outliers :    3.321 %.  ->  Not\n",
      "feature 10     outliers :    0.281 %.  ->  Not\n",
      "feature 11     outliers :    3.461 %.  ->  Not\n",
      "feature 12     outliers :    0.134 %.  ->  Normal Distribution\n",
      "feature 13     outliers :    0.702 %.  ->  Not\n",
      "feature 14     outliers :    0.201 %.  ->  Normal Distribution\n",
      "feature 15     outliers :    0.958 %.  ->  Not\n",
      "feature 16     outliers :    2.332 %.  ->  Not\n",
      "feature 17     outliers :    0.000 %.  ->  Normal Distribution\n",
      "feature 18     outliers :    0.610 %.  ->  Not\n",
      "feature 19     outliers :    3.272 %.  ->  Not\n",
      "feature 20     outliers :    3.552 %.  ->  Not\n",
      "feature 21     outliers :    3.711 %.  ->  Not\n",
      "feature 22     outliers :    3.461 %.  ->  Not\n",
      "feature 23     outliers :    0.031 %.  ->  Normal Distribution\n",
      "feature 24     outliers :    3.571 %.  ->  Not\n"
     ]
    }
   ],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    if(num_outliers[i] <= 0.27): \n",
    "        print(\"feature \" + str(i+1) + \"     outliers :    %.3f \" %num_outliers[i] + \"%.  ->  Normal Distribution\")\n",
    "    else:\n",
    "        print(\"feature \" + str(i+1) + \"     outliers :    %.3f \" %num_outliers[i] + \"%.  ->  Not\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little looser judgement. Feature 3, 12, 14 are \"somewhat close to normal\" distribution. Now I remove outliers again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because of feature 3, deleted row 1346.    Deleted value : 1283.250\n",
      "because of feature 3, deleted row 2617.    Deleted value : 4060.380\n",
      "because of feature 3, deleted row 3108.    Deleted value : 2463.840\n",
      "because of feature 3, deleted row 3261.    Deleted value : 1446.090\n",
      "because of feature 3, deleted row 4550.    Deleted value : 1805.400\n",
      "because of feature 3, deleted row 5016.    Deleted value : 1290.330\n",
      "because of feature 3, deleted row 6409.    Deleted value : 7129.560\n",
      "because of feature 3, deleted row 7164.    Deleted value : 2030.190\n",
      "because of feature 3, deleted row 7957.    Deleted value : 2318.700\n",
      "because of feature 3, deleted row 8618.    Deleted value : 2070.900\n",
      "because of feature 3, deleted row 12807.    Deleted value : 43910.160\n",
      "because of feature 3, deleted row 14062.    Deleted value : 1552.290\n",
      "because of feature 3, deleted row 14218.    Deleted value : 1761.150\n",
      "because of feature 3, deleted row 15299.    Deleted value : 1095.630\n",
      "because of feature 12, deleted row 693.    Deleted value : 899.000\n",
      "because of feature 12, deleted row 849.    Deleted value : 1273.000\n",
      "because of feature 12, deleted row 2603.    Deleted value : 555.000\n",
      "because of feature 12, deleted row 2636.    Deleted value : 358.000\n",
      "because of feature 12, deleted row 3232.    Deleted value : 2227.000\n",
      "because of feature 12, deleted row 3585.    Deleted value : 377.000\n",
      "because of feature 12, deleted row 3997.    Deleted value : 1104.000\n",
      "because of feature 12, deleted row 4474.    Deleted value : 3498.000\n",
      "because of feature 12, deleted row 5218.    Deleted value : 690.000\n",
      "because of feature 12, deleted row 6138.    Deleted value : 484.000\n",
      "because of feature 12, deleted row 6319.    Deleted value : 2701.000\n",
      "because of feature 12, deleted row 6777.    Deleted value : 559.000\n",
      "because of feature 12, deleted row 7373.    Deleted value : 344.000\n",
      "because of feature 12, deleted row 8112.    Deleted value : 1292.000\n",
      "because of feature 12, deleted row 9618.    Deleted value : 401.000\n",
      "because of feature 12, deleted row 10110.    Deleted value : 2831.000\n",
      "because of feature 12, deleted row 10168.    Deleted value : 913.000\n",
      "because of feature 12, deleted row 11091.    Deleted value : 3275.000\n",
      "because of feature 12, deleted row 11318.    Deleted value : 334.000\n",
      "because of feature 12, deleted row 11637.    Deleted value : 462.000\n",
      "because of feature 12, deleted row 11704.    Deleted value : 344.000\n",
      "because of feature 12, deleted row 14208.    Deleted value : 10076.000\n",
      "because of feature 12, deleted row 14229.    Deleted value : 860.000\n",
      "because of feature 12, deleted row 15496.    Deleted value : 2102.000\n",
      "because of feature 12, deleted row 15513.    Deleted value : 446.000\n",
      "because of feature 12, deleted row 15524.    Deleted value : 603.000\n",
      "because of feature 12, deleted row 15893.    Deleted value : 5561.000\n",
      "because of feature 14, deleted row 120.    Deleted value : -5.536\n",
      "because of feature 14, deleted row 196.    Deleted value : -6.159\n",
      "because of feature 14, deleted row 323.    Deleted value : -5.000\n",
      "because of feature 14, deleted row 481.    Deleted value : -7.446\n",
      "because of feature 14, deleted row 562.    Deleted value : -5.173\n",
      "because of feature 14, deleted row 570.    Deleted value : -5.779\n",
      "because of feature 14, deleted row 970.    Deleted value : -5.827\n",
      "because of feature 14, deleted row 1183.    Deleted value : -5.606\n",
      "because of feature 14, deleted row 1202.    Deleted value : -5.432\n",
      "because of feature 14, deleted row 1240.    Deleted value : -5.951\n",
      "because of feature 14, deleted row 1316.    Deleted value : 6.063\n",
      "because of feature 14, deleted row 1329.    Deleted value : 6.063\n",
      "because of feature 14, deleted row 1357.    Deleted value : 5.902\n",
      "because of feature 14, deleted row 1380.    Deleted value : -5.282\n",
      "because of feature 14, deleted row 1651.    Deleted value : -6.006\n",
      "because of feature 14, deleted row 1686.    Deleted value : -4.959\n",
      "because of feature 14, deleted row 1755.    Deleted value : -5.340\n",
      "because of feature 14, deleted row 1809.    Deleted value : -5.164\n",
      "because of feature 14, deleted row 1973.    Deleted value : -5.368\n",
      "because of feature 14, deleted row 2000.    Deleted value : -5.432\n",
      "because of feature 14, deleted row 2104.    Deleted value : 5.604\n",
      "because of feature 14, deleted row 2503.    Deleted value : 6.921\n",
      "because of feature 14, deleted row 2561.    Deleted value : -4.976\n",
      "because of feature 14, deleted row 2662.    Deleted value : -5.699\n",
      "because of feature 14, deleted row 2871.    Deleted value : -5.633\n",
      "because of feature 14, deleted row 3015.    Deleted value : -4.963\n",
      "because of feature 14, deleted row 3112.    Deleted value : -5.053\n",
      "because of feature 14, deleted row 3141.    Deleted value : -6.224\n",
      "because of feature 14, deleted row 3403.    Deleted value : -5.659\n",
      "because of feature 14, deleted row 3814.    Deleted value : -4.927\n",
      "because of feature 14, deleted row 3927.    Deleted value : -5.006\n",
      "because of feature 14, deleted row 4107.    Deleted value : -4.897\n",
      "because of feature 14, deleted row 4258.    Deleted value : -5.000\n",
      "because of feature 14, deleted row 4427.    Deleted value : -5.136\n",
      "because of feature 14, deleted row 4510.    Deleted value : -5.910\n",
      "because of feature 14, deleted row 4549.    Deleted value : 5.971\n",
      "because of feature 14, deleted row 5262.    Deleted value : -5.622\n",
      "because of feature 14, deleted row 5595.    Deleted value : -5.464\n",
      "because of feature 14, deleted row 5732.    Deleted value : -5.380\n",
      "because of feature 14, deleted row 5757.    Deleted value : -6.779\n",
      "because of feature 14, deleted row 5787.    Deleted value : -5.054\n",
      "because of feature 14, deleted row 5915.    Deleted value : -4.972\n",
      "because of feature 14, deleted row 5919.    Deleted value : -5.160\n",
      "because of feature 14, deleted row 6125.    Deleted value : 6.060\n",
      "because of feature 14, deleted row 6130.    Deleted value : -5.361\n",
      "because of feature 14, deleted row 6249.    Deleted value : -5.000\n",
      "because of feature 14, deleted row 6297.    Deleted value : -6.740\n",
      "because of feature 14, deleted row 6303.    Deleted value : -5.416\n",
      "because of feature 14, deleted row 6315.    Deleted value : 6.836\n",
      "because of feature 14, deleted row 6512.    Deleted value : -5.642\n",
      "because of feature 14, deleted row 6640.    Deleted value : 5.495\n",
      "because of feature 14, deleted row 6804.    Deleted value : -4.986\n",
      "because of feature 14, deleted row 7030.    Deleted value : -5.756\n",
      "because of feature 14, deleted row 7183.    Deleted value : -5.160\n",
      "because of feature 14, deleted row 7199.    Deleted value : -6.198\n",
      "because of feature 14, deleted row 7261.    Deleted value : -5.016\n",
      "because of feature 14, deleted row 7263.    Deleted value : -5.465\n",
      "because of feature 14, deleted row 7315.    Deleted value : -6.393\n",
      "because of feature 14, deleted row 7351.    Deleted value : -5.419\n",
      "because of feature 14, deleted row 7420.    Deleted value : 5.735\n",
      "because of feature 14, deleted row 7434.    Deleted value : -5.133\n",
      "because of feature 14, deleted row 7437.    Deleted value : -5.757\n",
      "because of feature 14, deleted row 7438.    Deleted value : -6.199\n",
      "because of feature 14, deleted row 7438.    Deleted value : -5.112\n",
      "because of feature 14, deleted row 7497.    Deleted value : -5.313\n",
      "because of feature 14, deleted row 7499.    Deleted value : -5.098\n",
      "because of feature 14, deleted row 7670.    Deleted value : -4.896\n",
      "because of feature 14, deleted row 7689.    Deleted value : -5.005\n",
      "because of feature 14, deleted row 7773.    Deleted value : 6.154\n",
      "because of feature 14, deleted row 7814.    Deleted value : -5.838\n",
      "because of feature 14, deleted row 7834.    Deleted value : 6.068\n",
      "because of feature 14, deleted row 7844.    Deleted value : -5.349\n",
      "because of feature 14, deleted row 8146.    Deleted value : 6.389\n",
      "because of feature 14, deleted row 8226.    Deleted value : -6.024\n",
      "because of feature 14, deleted row 8284.    Deleted value : -6.326\n",
      "because of feature 14, deleted row 8324.    Deleted value : -5.927\n",
      "because of feature 14, deleted row 8372.    Deleted value : -6.313\n",
      "because of feature 14, deleted row 8585.    Deleted value : -5.160\n",
      "because of feature 14, deleted row 8811.    Deleted value : -5.195\n",
      "because of feature 14, deleted row 9015.    Deleted value : 5.728\n",
      "because of feature 14, deleted row 9210.    Deleted value : -4.995\n",
      "because of feature 14, deleted row 9326.    Deleted value : 5.684\n",
      "because of feature 14, deleted row 9326.    Deleted value : -5.084\n",
      "because of feature 14, deleted row 9334.    Deleted value : -5.287\n",
      "because of feature 14, deleted row 9395.    Deleted value : -5.459\n",
      "because of feature 14, deleted row 9429.    Deleted value : 7.294\n",
      "because of feature 14, deleted row 9658.    Deleted value : -5.763\n",
      "because of feature 14, deleted row 9830.    Deleted value : -5.157\n",
      "because of feature 14, deleted row 9849.    Deleted value : -4.987\n",
      "because of feature 14, deleted row 10313.    Deleted value : 5.718\n",
      "because of feature 14, deleted row 10316.    Deleted value : -7.030\n",
      "because of feature 14, deleted row 10368.    Deleted value : -5.349\n",
      "because of feature 14, deleted row 10410.    Deleted value : -7.225\n",
      "because of feature 14, deleted row 10587.    Deleted value : -4.972\n",
      "because of feature 14, deleted row 10624.    Deleted value : 7.399\n",
      "because of feature 14, deleted row 10867.    Deleted value : -4.914\n",
      "because of feature 14, deleted row 10898.    Deleted value : 6.029\n",
      "because of feature 14, deleted row 10908.    Deleted value : -5.953\n",
      "because of feature 14, deleted row 10948.    Deleted value : -5.596\n",
      "because of feature 14, deleted row 10948.    Deleted value : 6.521\n",
      "because of feature 14, deleted row 11379.    Deleted value : -5.440\n",
      "because of feature 14, deleted row 11458.    Deleted value : 7.151\n",
      "because of feature 14, deleted row 11604.    Deleted value : -5.333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because of feature 14, deleted row 11712.    Deleted value : -5.410\n",
      "because of feature 14, deleted row 11757.    Deleted value : -5.018\n",
      "because of feature 14, deleted row 11821.    Deleted value : 5.730\n",
      "because of feature 14, deleted row 11846.    Deleted value : -5.029\n",
      "because of feature 14, deleted row 12314.    Deleted value : -5.451\n",
      "because of feature 14, deleted row 12334.    Deleted value : -5.974\n",
      "because of feature 14, deleted row 12426.    Deleted value : -4.968\n",
      "because of feature 14, deleted row 13089.    Deleted value : -5.834\n",
      "because of feature 14, deleted row 13487.    Deleted value : 5.909\n",
      "because of feature 14, deleted row 13722.    Deleted value : -4.952\n",
      "because of feature 14, deleted row 13839.    Deleted value : -5.104\n",
      "because of feature 14, deleted row 14004.    Deleted value : -5.103\n",
      "because of feature 14, deleted row 14088.    Deleted value : 5.682\n",
      "because of feature 14, deleted row 14108.    Deleted value : 6.339\n",
      "because of feature 14, deleted row 14451.    Deleted value : -5.017\n",
      "because of feature 14, deleted row 14599.    Deleted value : -5.168\n",
      "because of feature 14, deleted row 14710.    Deleted value : 5.858\n",
      "because of feature 14, deleted row 14786.    Deleted value : -5.968\n",
      "because of feature 14, deleted row 14957.    Deleted value : -5.276\n",
      "because of feature 14, deleted row 15013.    Deleted value : -5.379\n",
      "because of feature 14, deleted row 15080.    Deleted value : 6.332\n",
      "because of feature 14, deleted row 15381.    Deleted value : -5.286\n",
      "because of feature 14, deleted row 15482.    Deleted value : -5.335\n",
      "because of feature 14, deleted row 15524.    Deleted value : -5.453\n",
      "because of feature 14, deleted row 15524.    Deleted value : 5.528\n",
      "because of feature 14, deleted row 15770.    Deleted value : -4.940\n",
      "because of feature 14, deleted row 15864.    Deleted value : -6.184\n",
      "because of feature 14, deleted row 16118.    Deleted value : 5.975\n"
     ]
    }
   ],
   "source": [
    "for i in [7, 16, 22, 2, 11, 13]:\n",
    "    j = 0\n",
    "    while (j < X.shape[0]):\n",
    "        if(X[j][i] > mean[i] + 3.0*std[i] or X[j][i] < mean[i] - 3.0*std[i]):\n",
    "            val = X[j][i]\n",
    "            X = np.delete(X, j, 0)\n",
    "            y = np.delete(y, j, 0)\n",
    "            print(\"because of feature %d, deleted row %d.    Deleted value : %.3f\" %(i+1, j, val))\n",
    "        else:\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16206, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below, I was just re-tuning XGBClassifier with the improved data. However, the way I removed outliers were wrong so it's not anything valid. (commented when creating the report 10/31)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb01 = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time xgb01.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %f' % metrics.accuracy_score(y_test, xgb2.predict(X_test)))\n",
    "print('AUC: %f' %metrics.roc_auc_score(y_test, xgb2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission21 = pd.DataFrame(xgb2.predict_proba(X_pred)[:, 1], columns = ['Y']) \n",
    "y_submission21['Id'] = X_pred_data['Id']\n",
    "y_submission21 = y_submission21.reindex(columns=[\"Id\", \"Y\"])\n",
    "y_submission21.to_csv(\"submission21_uk734.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = [\n",
    " {'max_depth':[5, 6],\n",
    " 'min_child_weight':[5, 6],\n",
    " 'gamma':[0.1],\n",
    " 'subsample':[0.8],\n",
    " 'colsample_bytree':[0.6],\n",
    " 'reg_alpha':[1], \n",
    " 'objective': ['binary:logistic'],\n",
    " 'scale_pos_weight':[1],\n",
    " 'learning_rate': [0.1],\n",
    " 'n_estimators': [1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'max_depth': [5, 6], 'min_child_weight': [5, 6], 'gamma': [0.1], 'subsample': [0.8], 'colsample_bytree': [0.6], 'reg_alpha': [1], 'objective': ['binary:logistic'], 'scale_pos_weight': [1], 'learning_rate': [0.1], 'n_estimators': [1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1 = GridSearchCV(xgb.XGBClassifier(), param_grid = params1, scoring='roc_auc', n_jobs=-1, iid=False, cv=3, verbose = 2)\n",
    "grid1.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "    xgb1 = grid1.best_estimator_\n",
    "print(xgb1.get_params()['max_depth'])\n",
    "print(xgb1.get_params()['min_child_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = [\n",
    " {'max_depth':[6, 7],\n",
    " 'min_child_weight':[4, 5],\n",
    " 'gamma':[0.1],\n",
    " 'subsample':[0.8],\n",
    " 'colsample_bytree':[0.6],\n",
    " 'reg_alpha':[1], \n",
    " 'objective': ['binary:logistic'],\n",
    " 'scale_pos_weight':[1],\n",
    " 'learning_rate': [0.1],\n",
    " 'n_estimators': [1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'max_depth': [6, 7], 'min_child_weight': [4, 5], 'gamma': [0.1], 'subsample': [0.8], 'colsample_bytree': [0.6], 'reg_alpha': [1], 'objective': ['binary:logistic'], 'scale_pos_weight': [1], 'learning_rate': [0.1], 'n_estimators': [1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2 = GridSearchCV(xgb.XGBClassifier(), param_grid = params2, scoring='roc_auc', n_jobs=-1, iid=False, cv=3, verbose = 2)\n",
    "grid2.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "xgb2 = grid2.best_estimator_\n",
    "print(xgb2.get_params()['max_depth'])\n",
    "print(xgb2.get_params()['min_child_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = [\n",
    " {'max_depth':[6],\n",
    " 'min_child_weight':[3, 4],\n",
    " 'gamma':[0.1],\n",
    " 'subsample':[0.8],\n",
    " 'colsample_bytree':[0.6],\n",
    " 'reg_alpha':[1], \n",
    " 'objective': ['binary:logistic'],\n",
    " 'scale_pos_weight':[1],\n",
    " 'learning_rate': [0.1],\n",
    " 'n_estimators': [1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   57.4s remaining:   57.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'max_depth': [6], 'min_child_weight': [3, 4], 'gamma': [0.1], 'subsample': [0.8], 'colsample_bytree': [0.6], 'reg_alpha': [1], 'objective': ['binary:logistic'], 'scale_pos_weight': [1], 'learning_rate': [0.1], 'n_estimators': [1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3 = GridSearchCV(xgb.XGBClassifier(), param_grid = params3, scoring='roc_auc', n_jobs=-1, iid=False, cv=3, verbose = 2)\n",
    "grid3.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "xgb3 = grid3.best_estimator_\n",
    "print(xgb3.get_params()['max_depth'])\n",
    "print(xgb3.get_params()['min_child_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4 = [\n",
    " {'max_depth':[6],\n",
    " 'min_child_weight':[4],\n",
    " 'gamma':[0, 0.1, 0.2],\n",
    " 'subsample':[0.8],\n",
    " 'colsample_bytree':[0.6],\n",
    " 'reg_alpha':[1], \n",
    " 'objective': ['binary:logistic'],\n",
    " 'scale_pos_weight':[1],\n",
    " 'learning_rate': [0.1],\n",
    " 'n_estimators': [1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:  1.7min remaining:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'max_depth': [6], 'min_child_weight': [4], 'gamma': [0, 0.1, 0.2], 'subsample': [0.8], 'colsample_bytree': [0.6], 'reg_alpha': [1], 'objective': ['binary:logistic'], 'scale_pos_weight': [1], 'learning_rate': [0.1], 'n_estimators': [1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid4 = GridSearchCV(xgb.XGBClassifier(), param_grid = params4, scoring='roc_auc', n_jobs=-1, iid=False, cv=3, verbose = 2)\n",
    "grid4.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "xgb4 = grid4.best_estimator_\n",
    "print(xgb4.get_params()['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.6, gamma=0.1,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=4, missing=None, n_estimators=1000, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb4.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.965475\n",
      "AUC: 0.737617\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %f' % metrics.accuracy_score(y_test, xgb4.predict(X_test)))\n",
    "print('AUC: %f' %metrics.roc_auc_score(y_test, xgb4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a great improvement. I should try submitting at this point. I may achieve better score by further tuning it model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission22 = pd.DataFrame(xgb4.predict_proba(X_pred)[:, 1], columns = ['Y']) \n",
    "y_submission22['Id'] = X_pred_data['Id']\n",
    "y_submission22 = y_submission22.reindex(columns=[\"Id\", \"Y\"])\n",
    "y_submission22.to_csv(\"submission22_uk734.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params5 = [\n",
    " {'max_depth':[6],\n",
    " 'min_child_weight':[4],\n",
    " 'gamma':[0.1],\n",
    " 'subsample':[0.7, 0.8],\n",
    " 'colsample_bytree':[0.6, 0.7],\n",
    " 'reg_alpha':[1], \n",
    " 'objective': ['binary:logistic'],\n",
    " 'scale_pos_weight':[1],\n",
    " 'learning_rate': [0.1],\n",
    " 'n_estimators': [1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'max_depth': [6], 'min_child_weight': [4], 'gamma': [0.1], 'subsample': [0.7, 0.8], 'colsample_bytree': [0.6, 0.7], 'reg_alpha': [1], 'objective': ['binary:logistic'], 'scale_pos_weight': [1], 'learning_rate': [0.1], 'n_estimators': [1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid5 = GridSearchCV(xgb.XGBClassifier(), param_grid = params5, scoring='roc_auc', n_jobs=-1, iid=False, cv=3, verbose = 2)\n",
    "grid5.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "xgb5 = grid5.best_estimator_\n",
    "print(xgb5.get_params()['subsample'])\n",
    "print(xgb5.get_params()['colsample_bytree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params6 = [\n",
    " {'max_depth':[6],\n",
    " 'min_child_weight':[4],\n",
    " 'gamma':[0.1],\n",
    " 'subsample':[0.8, 0.9],\n",
    " 'colsample_bytree':[0.5, 0.6],\n",
    " 'reg_alpha':[1], \n",
    " 'objective': ['binary:logistic'],\n",
    " 'scale_pos_weight':[1],\n",
    " 'learning_rate': [0.1],\n",
    " 'n_estimators': [1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'max_depth': [6], 'min_child_weight': [4], 'gamma': [0.1], 'subsample': [0.8, 0.9], 'colsample_bytree': [0.5, 0.6], 'reg_alpha': [1], 'objective': ['binary:logistic'], 'scale_pos_weight': [1], 'learning_rate': [0.1], 'n_estimators': [1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid6 = GridSearchCV(xgb.XGBClassifier(), param_grid = params6, scoring='roc_auc', n_jobs=-1, iid=False, cv=3, verbose = 2)\n",
    "grid6.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "xgb6 = grid6.best_estimator_\n",
    "print(xgb6.get_params()['subsample'])\n",
    "print(xgb6.get_params()['colsample_bytree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params7 = [\n",
    " {'max_depth':[6],\n",
    " 'min_child_weight':[4],\n",
    " 'gamma':[0.1],\n",
    " 'subsample':[0.8],\n",
    " 'colsample_bytree':[0.6],\n",
    " 'reg_alpha':[0.5, 1, 1.5], \n",
    " 'objective': ['binary:logistic'],\n",
    " 'scale_pos_weight':[1],\n",
    " 'learning_rate': [0.1],\n",
    " 'n_estimators': [1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   48.9s remaining:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'max_depth': [6], 'min_child_weight': [4], 'gamma': [0.1], 'subsample': [0.8], 'colsample_bytree': [0.6], 'reg_alpha': [0.5, 1], 'objective': ['binary:logistic'], 'scale_pos_weight': [1], 'learning_rate': [0.1], 'n_estimators': [1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid7 = GridSearchCV(xgb.XGBClassifier(), param_grid = params7, scoring='roc_auc', n_jobs=-1, iid=False, cv=3, verbose = 2)\n",
    "grid7.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "xgb7 = grid7.best_estimator_\n",
    "print(xgb7.get_params()['reg_alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params8 = [\n",
    " {'max_depth':[6],\n",
    " 'min_child_weight':[4],\n",
    " 'gamma':[0.1],\n",
    " 'subsample':[0.8],\n",
    " 'colsample_bytree':[0.6],\n",
    " 'reg_alpha':[1], \n",
    " 'objective': ['binary:logistic'],\n",
    " 'scale_pos_weight':[1],\n",
    " 'learning_rate': [0.05, 0.1],\n",
    " 'n_estimators': [1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:  1.0min remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'max_depth': [6], 'min_child_weight': [4], 'gamma': [0.1], 'subsample': [0.8], 'colsample_bytree': [0.6], 'reg_alpha': [1], 'objective': ['binary:logistic'], 'scale_pos_weight': [1], 'learning_rate': [0.05, 0.1], 'n_estimators': [1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid8 = GridSearchCV(xgb.XGBClassifier(), param_grid = params8, scoring='roc_auc', n_jobs=-1, iid=False, cv=3, verbose = 2)\n",
    "grid8.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "xgb8 = grid8.best_estimator_\n",
    "print(xgb8.get_params()['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "params9 = [\n",
    " {'max_depth':[6],\n",
    " 'min_child_weight':[4],\n",
    " 'gamma':[0.1],\n",
    " 'subsample':[0.8],\n",
    " 'colsample_bytree':[0.6],\n",
    " 'reg_alpha':[1], \n",
    " 'objective': ['binary:logistic'],\n",
    " 'scale_pos_weight':[1],\n",
    " 'learning_rate': [0.05],\n",
    " 'n_estimators': [500, 1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   29.5s remaining:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'max_depth': [6], 'min_child_weight': [4], 'gamma': [0.1], 'subsample': [0.8], 'colsample_bytree': [0.6], 'reg_alpha': [1], 'objective': ['binary:logistic'], 'scale_pos_weight': [1], 'learning_rate': [0.05], 'n_estimators': [500, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid9 = GridSearchCV(xgb.XGBClassifier(), param_grid = params9, scoring='roc_auc', n_jobs=-1, iid=False, cv=3, verbose = 2)\n",
    "grid9.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "xgb9 = grid9.best_estimator_\n",
    "print(xgb9.get_params()['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.963009\n",
      "AUC: 0.726545\n"
     ]
    }
   ],
   "source": [
    "xgb9.fit(X_train, y_train.ravel())\n",
    "print('Accuracy: %f' % metrics.accuracy_score(y_test, xgb9.predict(X_test)))\n",
    "print('AUC: %f' %metrics.roc_auc_score(y_test, xgb9.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission23 = pd.DataFrame(xgb9.predict_proba(X_pred)[:, 1], columns = ['Y']) \n",
    "y_submission23['Id'] = X_pred_data['Id']\n",
    "y_submission23 = y_submission23.reindex(columns=[\"Id\", \"Y\"])\n",
    "y_submission23.to_csv(\"submission23_uk734.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid9' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cabe0844466b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxgb10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AUC: %f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid9' is not defined"
     ]
    }
   ],
   "source": [
    "xgb10 = grid9.best_estimator_\n",
    "xgb10.fit(X_train, y_train.ravel())\n",
    "print('Accuracy: %f' % metrics.accuracy_score(y_test, xgb10.predict(X_test)))\n",
    "print('AUC: %f' %metrics.roc_auc_score(y_test, xgb10.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission24 = pd.DataFrame(xgb10.predict_proba(X_pred)[:, 1], columns = ['Y']) \n",
    "y_submission24['Id'] = X_pred_data['Id']\n",
    "y_submission24 = y_submission24.reindex(columns=[\"Id\", \"Y\"])\n",
    "y_submission24.to_csv(\"submission24_uk734.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, matolotlib doesn't work well with xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
